// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        (unknown)
// source: google/monitoring/v3/common.proto

package monitoringpb

import (
	distribution "google.golang.org/genproto/googleapis/api/distribution"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	durationpb "google.golang.org/protobuf/types/known/durationpb"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Specifies an ordering relationship on two arguments, called `left` and
// `right`.
type ComparisonType int32

const (
	// No ordering relationship is specified.
	ComparisonType_COMPARISON_UNSPECIFIED ComparisonType = 0
	// True if the left argument is greater than the right argument.
	ComparisonType_COMPARISON_GT ComparisonType = 1
	// True if the left argument is greater than or equal to the right argument.
	ComparisonType_COMPARISON_GE ComparisonType = 2
	// True if the left argument is less than the right argument.
	ComparisonType_COMPARISON_LT ComparisonType = 3
	// True if the left argument is less than or equal to the right argument.
	ComparisonType_COMPARISON_LE ComparisonType = 4
	// True if the left argument is equal to the right argument.
	ComparisonType_COMPARISON_EQ ComparisonType = 5
	// True if the left argument is not equal to the right argument.
	ComparisonType_COMPARISON_NE ComparisonType = 6
)

// Enum value maps for ComparisonType.
var (
	ComparisonType_name = map[int32]string{
		0: "COMPARISON_UNSPECIFIED",
		1: "COMPARISON_GT",
		2: "COMPARISON_GE",
		3: "COMPARISON_LT",
		4: "COMPARISON_LE",
		5: "COMPARISON_EQ",
		6: "COMPARISON_NE",
	}
	ComparisonType_value = map[string]int32{
		"COMPARISON_UNSPECIFIED": 0,
		"COMPARISON_GT":          1,
		"COMPARISON_GE":          2,
		"COMPARISON_LT":          3,
		"COMPARISON_LE":          4,
		"COMPARISON_EQ":          5,
		"COMPARISON_NE":          6,
	}
)

func (x ComparisonType) Enum() *ComparisonType {
	p := new(ComparisonType)
	*p = x
	return p
}

func (x ComparisonType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ComparisonType) Descriptor() protoreflect.EnumDescriptor {
	return file_google_monitoring_v3_common_proto_enumTypes[0].Descriptor()
}

func (ComparisonType) Type() protoreflect.EnumType {
	return &file_google_monitoring_v3_common_proto_enumTypes[0]
}

func (x ComparisonType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ComparisonType.Descriptor instead.
func (ComparisonType) EnumDescriptor() ([]byte, []int) {
	return file_google_monitoring_v3_common_proto_rawDescGZIP(), []int{0}
}

// The tier of service for a Metrics Scope. Please see the
// [service tiers
// documentation](https://cloud.google.com/monitoring/workspaces/tiers) for more
// details.
//
// Deprecated: Marked as deprecated in google/monitoring/v3/common.proto.
type ServiceTier int32

const (
	// An invalid sentinel value, used to indicate that a tier has not
	// been provided explicitly.
	ServiceTier_SERVICE_TIER_UNSPECIFIED ServiceTier = 0
	// The Cloud Monitoring Basic tier, a free tier of service that provides basic
	// features, a moderate allotment of logs, and access to built-in metrics.
	// A number of features are not available in this tier. For more details,
	// see [the service tiers
	// documentation](https://cloud.google.com/monitoring/workspaces/tiers).
	ServiceTier_SERVICE_TIER_BASIC ServiceTier = 1
	// The Cloud Monitoring Premium tier, a higher, more expensive tier of service
	// that provides access to all Cloud Monitoring features, lets you use Cloud
	// Monitoring with AWS accounts, and has a larger allotments for logs and
	// metrics. For more details, see [the service tiers
	// documentation](https://cloud.google.com/monitoring/workspaces/tiers).
	ServiceTier_SERVICE_TIER_PREMIUM ServiceTier = 2
)

// Enum value maps for ServiceTier.
var (
	ServiceTier_name = map[int32]string{
		0: "SERVICE_TIER_UNSPECIFIED",
		1: "SERVICE_TIER_BASIC",
		2: "SERVICE_TIER_PREMIUM",
	}
	ServiceTier_value = map[string]int32{
		"SERVICE_TIER_UNSPECIFIED": 0,
		"SERVICE_TIER_BASIC":       1,
		"SERVICE_TIER_PREMIUM":     2,
	}
)

func (x ServiceTier) Enum() *ServiceTier {
	p := new(ServiceTier)
	*p = x
	return p
}

func (x ServiceTier) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ServiceTier) Descriptor() protoreflect.EnumDescriptor {
	return file_google_monitoring_v3_common_proto_enumTypes[1].Descriptor()
}

func (ServiceTier) Type() protoreflect.EnumType {
	return &file_google_monitoring_v3_common_proto_enumTypes[1]
}

func (x ServiceTier) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ServiceTier.Descriptor instead.
func (ServiceTier) EnumDescriptor() ([]byte, []int) {
	return file_google_monitoring_v3_common_proto_rawDescGZIP(), []int{1}
}

// The `Aligner` specifies the operation that will be applied to the data
// points in each alignment period in a time series. Except for
// `ALIGN_NONE`, which specifies that no operation be applied, each alignment
// operation replaces the set of data values in each alignment period with
// a single value: the result of applying the operation to the data values.
// An aligned time series has a single data value at the end of each
// `alignment_period`.
//
// An alignment operation can change the data type of the values, too. For
// example, if you apply a counting operation to boolean values, the data
// `value_type` in the original time series is `BOOLEAN`, but the `value_type`
// in the aligned result is `INT64`.
type Aggregation_Aligner int32

const (
	// No alignment. Raw data is returned. Not valid if cross-series reduction
	// is requested. The `value_type` of the result is the same as the
	// `value_type` of the input.
	Aggregation_ALIGN_NONE Aggregation_Aligner = 0
	// Align and convert to
	// [DELTA][google.api.MetricDescriptor.MetricKind.DELTA].
	// The output is `delta = y1 - y0`.
	//
	// This alignment is valid for
	// [CUMULATIVE][google.api.MetricDescriptor.MetricKind.CUMULATIVE] and
	// `DELTA` metrics. If the selected alignment period results in periods
	// with no data, then the aligned value for such a period is created by
	// interpolation. The `value_type`  of the aligned result is the same as
	// the `value_type` of the input.
	Aggregation_ALIGN_DELTA Aggregation_Aligner = 1
	// Align and convert to a rate. The result is computed as
	// `rate = (y1 - y0)/(t1 - t0)`, or "delta over time".
	// Think of this aligner as providing the slope of the line that passes
	// through the value at the start and at the end of the `alignment_period`.
	//
	// This aligner is valid for `CUMULATIVE`
	// and `DELTA` metrics with numeric values. If the selected alignment
	// period results in periods with no data, then the aligned value for
	// such a period is created by interpolation. The output is a `GAUGE`
	// metric with `value_type` `DOUBLE`.
	//
	// If, by "rate", you mean "percentage change", see the
	// `ALIGN_PERCENT_CHANGE` aligner instead.
	Aggregation_ALIGN_RATE Aggregation_Aligner = 2
	// Align by interpolating between adjacent points around the alignment
	// period boundary. This aligner is valid for `GAUGE` metrics with
	// numeric values. The `value_type` of the aligned result is the same as the
	// `value_type` of the input.
	Aggregation_ALIGN_INTERPOLATE Aggregation_Aligner = 3
	// Align by moving the most recent data point before the end of the
	// alignment period to the boundary at the end of the alignment
	// period. This aligner is valid for `GAUGE` metrics. The `value_type` of
	// the aligned result is the same as the `value_type` of the input.
	Aggregation_ALIGN_NEXT_OLDER Aggregation_Aligner = 4
	// Align the time series by returning the minimum value in each alignment
	// period. This aligner is valid for `GAUGE` and `DELTA` metrics with
	// numeric values. The `value_type` of the aligned result is the same as
	// the `value_type` of the input.
	Aggregation_ALIGN_MIN Aggregation_Aligner = 10
	// Align the time series by returning the maximum value in each alignment
	// period. This aligner is valid for `GAUGE` and `DELTA` metrics with
	// numeric values. The `value_type` of the aligned result is the same as
	// the `value_type` of the input.
	Aggregation_ALIGN_MAX Aggregation_Aligner = 11
	// Align the time series by returning the mean value in each alignment
	// period. This aligner is valid for `GAUGE` and `DELTA` metrics with
	// numeric values. The `value_type` of the aligned result is `DOUBLE`.
	Aggregation_ALIGN_MEAN Aggregation_Aligner = 12
	// Align the time series by returning the number of values in each alignment
	// period. This aligner is valid for `GAUGE` and `DELTA` metrics with
	// numeric or Boolean values. The `value_type` of the aligned result is
	// `INT64`.
	Aggregation_ALIGN_COUNT Aggregation_Aligner = 13
	// Align the time series by returning the sum of the values in each
	// alignment period. This aligner is valid for `GAUGE` and `DELTA`
	// metrics with numeric and distribution values. The `value_type` of the
	// aligned result is the same as the `value_type` of the input.
	Aggregation_ALIGN_SUM Aggregation_Aligner = 14
	// Align the time series by returning the standard deviation of the values
	// in each alignment period. This aligner is valid for `GAUGE` and
	// `DELTA` metrics with numeric values. The `value_type` of the output is
	// `DOUBLE`.
	Aggregation_ALIGN_STDDEV Aggregation_Aligner = 15
	// Align the time series by returning the number of `True` values in
	// each alignment period. This aligner is valid for `GAUGE` metrics with
	// Boolean values. The `value_type` of the output is `INT64`.
	Aggregation_ALIGN_COUNT_TRUE Aggregation_Aligner = 16
	// Align the time series by returning the number of `False` values in
	// each alignment period. This aligner is valid for `GAUGE` metrics with
	// Boolean values. The `value_type` of the output is `INT64`.
	Aggregation_ALIGN_COUNT_FALSE Aggregation_Aligner = 24
	// Align the time series by returning the ratio of the number of `True`
	// values to the total number of values in each alignment period. This
	// aligner is valid for `GAUGE` metrics with Boolean values. The output
	// value is in the range [0.0, 1.0] and has `value_type` `DOUBLE`.
	Aggregation_ALIGN_FRACTION_TRUE Aggregation_Aligner = 17
	// Align the time series by using [percentile
	// aggregation](https://en.wikipedia.org/wiki/Percentile). The resulting
	// data point in each alignment period is the 99th percentile of all data
	// points in the period. This aligner is valid for `GAUGE` and `DELTA`
	// metrics with distribution values. The output is a `GAUGE` metric with
	// `value_type` `DOUBLE`.
	Aggregation_ALIGN_PERCENTILE_99 Aggregation_Aligner = 18
	// Align the time series by using [percentile
	// aggregation](https://en.wikipedia.org/wiki/Percentile). The resulting
	// data point in each alignment period is the 95th percentile of all data
	// points in the period. This aligner is valid for `GAUGE` and `DELTA`
	// metrics with distribution values. The output is a `GAUGE` metric with
	// `value_type` `DOUBLE`.
	Aggregation_ALIGN_PERCENTILE_95 Aggregation_Aligner = 19
	// Align the time series by using [percentile
	// aggregation](https://en.wikipedia.org/wiki/Percentile). The resulting
	// data point in each alignment period is the 50th percentile of all data
	// points in the period. This aligner is valid for `GAUGE` and `DELTA`
	// metrics with distribution values. The output is a `GAUGE` metric with
	// `value_type` `DOUBLE`.
	Aggregation_ALIGN_PERCENTILE_50 Aggregation_Aligner = 20
	// Align the time series by using [percentile
	// aggregation](https://en.wikipedia.org/wiki/Percentile). The resulting
	// data point in each alignment period is the 5th percentile of all data
	// points in the period. This aligner is valid for `GAUGE` and `DELTA`
	// metrics with distribution values. The output is a `GAUGE` metric with
	// `value_type` `DOUBLE`.
	Aggregation_ALIGN_PERCENTILE_05 Aggregation_Aligner = 21
	// Align and convert to a percentage change. This aligner is valid for
	// `GAUGE` and `DELTA` metrics with numeric values. This alignment returns
	// `((current - previous)/previous) * 100`, where the value of `previous` is
	// determined based on the `alignment_period`.
	//
	// If the values of `current` and `previous` are both 0, then the returned
	// value is 0. If only `previous` is 0, the returned value is infinity.
	//
	// A 10-minute moving mean is computed at each point of the alignment period
	// prior to the above calculation to smooth the metric and prevent false
	// positives from very short-lived spikes. The moving mean is only
	// applicable for data whose values are `>= 0`. Any values `< 0` are
	// treated as a missing datapoint, and are ignored. While `DELTA`
	// metrics are accepted by this alignment, special care should be taken that
	// the values for the metric will always be positive. The output is a
	// `GAUGE` metric with `value_type` `DOUBLE`.
	Aggregation_ALIGN_PERCENT_CHANGE Aggregation_Aligner = 23
)

// Enum value maps for Aggregation_Aligner.
var (
	Aggregation_Aligner_name = map[int32]string{
		0:  "ALIGN_NONE",
		1:  "ALIGN_DELTA",
		2:  "ALIGN_RATE",
		3:  "ALIGN_INTERPOLATE",
		4:  "ALIGN_NEXT_OLDER",
		10: "ALIGN_MIN",
		11: "ALIGN_MAX",
		12: "ALIGN_MEAN",
		13: "ALIGN_COUNT",
		14: "ALIGN_SUM",
		15: "ALIGN_STDDEV",
		16: "ALIGN_COUNT_TRUE",
		24: "ALIGN_COUNT_FALSE",
		17: "ALIGN_FRACTION_TRUE",
		18: "ALIGN_PERCENTILE_99",
		19: "ALIGN_PERCENTILE_95",
		20: "ALIGN_PERCENTILE_50",
		21: "ALIGN_PERCENTILE_05",
		23: "ALIGN_PERCENT_CHANGE",
	}
	Aggregation_Aligner_value = map[string]int32{
		"ALIGN_NONE":           0,
		"ALIGN_DELTA":          1,
		"ALIGN_RATE":           2,
		"ALIGN_INTERPOLATE":    3,
		"ALIGN_NEXT_OLDER":     4,
		"ALIGN_MIN":            10,
		"ALIGN_MAX":            11,
		"ALIGN_MEAN":           12,
		"ALIGN_COUNT":          13,
		"ALIGN_SUM":            14,
		"ALIGN_STDDEV":         15,
		"ALIGN_COUNT_TRUE":     16,
		"ALIGN_COUNT_FALSE":    24,
		"ALIGN_FRACTION_TRUE":  17,
		"ALIGN_PERCENTILE_99":  18,
		"ALIGN_PERCENTILE_95":  19,
		"ALIGN_PERCENTILE_50":  20,
		"ALIGN_PERCENTILE_05":  21,
		"ALIGN_PERCENT_CHANGE": 23,
	}
)

func (x Aggregation_Aligner) Enum() *Aggregation_Aligner {
	p := new(Aggregation_Aligner)
	*p = x
	return p
}

func (x Aggregation_Aligner) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Aggregation_Aligner) Descriptor() protoreflect.EnumDescriptor {
	return file_google_monitoring_v3_common_proto_enumTypes[2].Descriptor()
}

func (Aggregation_Aligner) Type() protoreflect.EnumType {
	return &file_google_monitoring_v3_common_proto_enumTypes[2]
}

func (x Aggregation_Aligner) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Aggregation_Aligner.Descriptor instead.
func (Aggregation_Aligner) EnumDescriptor() ([]byte, []int) {
	return file_google_monitoring_v3_common_proto_rawDescGZIP(), []int{2, 0}
}

// A Reducer operation describes how to aggregate data points from multiple
// time series into a single time series, where the value of each data point
// in the resulting series is a function of all the already aligned values in
// the input time series.
type Aggregation_Reducer int32

const (
	// No cross-time series reduction. The output of the `Aligner` is
	// returned.
	Aggregation_REDUCE_NONE Aggregation_Reducer = 0
	// Reduce by computing the mean value across time series for each
	// alignment period. This reducer is valid for
	// [DELTA][google.api.MetricDescriptor.MetricKind.DELTA] and
	// [GAUGE][google.api.MetricDescriptor.MetricKind.GAUGE] metrics with
	// numeric or distribution values. The `value_type` of the output is
	// [DOUBLE][google.api.MetricDescriptor.ValueType.DOUBLE].
	Aggregation_REDUCE_MEAN Aggregation_Reducer = 1
	// Reduce by computing the minimum value across time series for each
	// alignment period. This reducer is valid for `DELTA` and `GAUGE` metrics
	// with numeric values. The `value_type` of the output is the same as the
	// `value_type` of the input.
	Aggregation_REDUCE_MIN Aggregation_Reducer = 2
	// Reduce by computing the maximum value across time series for each
	// alignment period. This reducer is valid for `DELTA` and `GAUGE` metrics
	// with numeric values. The `value_type` of the output is the same as the
	// `value_type` of the input.
	Aggregation_REDUCE_MAX Aggregation_Reducer = 3
	// Reduce by computing the sum across time series for each
	// alignment period. This reducer is valid for `DELTA` and `GAUGE` metrics
	// with numeric and distribution values. The `value_type` of the output is
	// the same as the `value_type` of the input.
	Aggregation_REDUCE_SUM Aggregation_Reducer = 4
	// Reduce by computing the standard deviation across time series
	// for each alignment period. This reducer is valid for `DELTA` and
	// `GAUGE` metrics with numeric or distribution values. The `value_type`
	// of the output is `DOUBLE`.
	Aggregation_REDUCE_STDDEV Aggregation_Reducer = 5
	// Reduce by computing the number of data points across time series
	// for each alignment period. This reducer is valid for `DELTA` and
	// `GAUGE` metrics of numeric, Boolean, distribution, and string
	// `value_type`. The `value_type` of the output is `INT64`.
	Aggregation_REDUCE_COUNT Aggregation_Reducer = 6
	// Reduce by computing the number of `True`-valued data points across time
	// series for each alignment period. This reducer is valid for `DELTA` and
	// `GAUGE` metrics of Boolean `value_type`. The `value_type` of the output
	// is `INT64`.
	Aggregation_REDUCE_COUNT_TRUE Aggregation_Reducer = 7
	// Reduce by computing the number of `False`-valued data points across time
	// series for each alignment period. This reducer is valid for `DELTA` and
	// `GAUGE` metrics of Boolean `value_type`. The `value_type` of the output
	// is `INT64`.
	Aggregation_REDUCE_COUNT_FALSE Aggregation_Reducer = 15
	// Reduce by computing the ratio of the number of `True`-valued data points
	// to the total number of data points for each alignment period. This
	// reducer is valid for `DELTA` and `GAUGE` metrics of Boolean `value_type`.
	// The output value is in the range [0.0, 1.0] and has `value_type`
	// `DOUBLE`.
	Aggregation_REDUCE_FRACTION_TRUE Aggregation_Reducer = 8
	// Reduce by computing the [99th
	// percentile](https://en.wikipedia.org/wiki/Percentile) of data points
	// across time series for each alignment period. This reducer is valid for
	// `GAUGE` and `DELTA` metrics of numeric and distribution type. The value
	// of the output is `DOUBLE`.
	Aggregation_REDUCE_PERCENTILE_99 Aggregation_Reducer = 9
	// Reduce by computing the [95th
	// percentile](https://en.wikipedia.org/wiki/Percentile) of data points
	// across time series for each alignment period. This reducer is valid for
	// `GAUGE` and `DELTA` metrics of numeric and distribution type. The value
	// of the output is `DOUBLE`.
	Aggregation_REDUCE_PERCENTILE_95 Aggregation_Reducer = 10
	// Reduce by computing the [50th
	// percentile](https://en.wikipedia.org/wiki/Percentile) of data points
	// across time series for each alignment period. This reducer is valid for
	// `GAUGE` and `DELTA` metrics of numeric and distribution type. The value
	// of the output is `DOUBLE`.
	Aggregation_REDUCE_PERCENTILE_50 Aggregation_Reducer = 11
	// Reduce by computing the [5th
	// percentile](https://en.wikipedia.org/wiki/Percentile) of data points
	// across time series for each alignment period. This reducer is valid for
	// `GAUGE` and `DELTA` metrics of numeric and distribution type. The value
	// of the output is `DOUBLE`.
	Aggregation_REDUCE_PERCENTILE_05 Aggregation_Reducer = 12
)

// Enum value maps for Aggregation_Reducer.
var (
	Aggregation_Reducer_name = map[int32]string{
		0:  "REDUCE_NONE",
		1:  "REDUCE_MEAN",
		2:  "REDUCE_MIN",
		3:  "REDUCE_MAX",
		4:  "REDUCE_SUM",
		5:  "REDUCE_STDDEV",
		6:  "REDUCE_COUNT",
		7:  "REDUCE_COUNT_TRUE",
		15: "REDUCE_COUNT_FALSE",
		8:  "REDUCE_FRACTION_TRUE",
		9:  "REDUCE_PERCENTILE_99",
		10: "REDUCE_PERCENTILE_95",
		11: "REDUCE_PERCENTILE_50",
		12: "REDUCE_PERCENTILE_05",
	}
	Aggregation_Reducer_value = map[string]int32{
		"REDUCE_NONE":          0,
		"REDUCE_MEAN":          1,
		"REDUCE_MIN":           2,
		"REDUCE_MAX":           3,
		"REDUCE_SUM":           4,
		"REDUCE_STDDEV":        5,
		"REDUCE_COUNT":         6,
		"REDUCE_COUNT_TRUE":    7,
		"REDUCE_COUNT_FALSE":   15,
		"REDUCE_FRACTION_TRUE": 8,
		"REDUCE_PERCENTILE_99": 9,
		"REDUCE_PERCENTILE_95": 10,
		"REDUCE_PERCENTILE_50": 11,
		"REDUCE_PERCENTILE_05": 12,
	}
)

func (x Aggregation_Reducer) Enum() *Aggregation_Reducer {
	p := new(Aggregation_Reducer)
	*p = x
	return p
}

func (x Aggregation_Reducer) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Aggregation_Reducer) Descriptor() protoreflect.EnumDescriptor {
	return file_google_monitoring_v3_common_proto_enumTypes[3].Descriptor()
}

func (Aggregation_Reducer) Type() protoreflect.EnumType {
	return &file_google_monitoring_v3_common_proto_enumTypes[3]
}

func (x Aggregation_Reducer) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Aggregation_Reducer.Descriptor instead.
func (Aggregation_Reducer) EnumDescriptor() ([]byte, []int) {
	return file_google_monitoring_v3_common_proto_rawDescGZIP(), []int{2, 1}
}

// A single strongly-typed value.
type TypedValue struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The typed value field.
	//
	// Types that are valid to be assigned to Value:
	//
	//	*TypedValue_BoolValue
	//	*TypedValue_Int64Value
	//	*TypedValue_DoubleValue
	//	*TypedValue_StringValue
	//	*TypedValue_DistributionValue
	Value         isTypedValue_Value `protobuf_oneof:"value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TypedValue) Reset() {
	*x = TypedValue{}
	mi := &file_google_monitoring_v3_common_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TypedValue) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TypedValue) ProtoMessage() {}

func (x *TypedValue) ProtoReflect() protoreflect.Message {
	mi := &file_google_monitoring_v3_common_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TypedValue.ProtoReflect.Descriptor instead.
func (*TypedValue) Descriptor() ([]byte, []int) {
	return file_google_monitoring_v3_common_proto_rawDescGZIP(), []int{0}
}

func (x *TypedValue) GetValue() isTypedValue_Value {
	if x != nil {
		return x.Value
	}
	return nil
}

func (x *TypedValue) GetBoolValue() bool {
	if x != nil {
		if x, ok := x.Value.(*TypedValue_BoolValue); ok {
			return x.BoolValue
		}
	}
	return false
}

func (x *TypedValue) GetInt64Value() int64 {
	if x != nil {
		if x, ok := x.Value.(*TypedValue_Int64Value); ok {
			return x.Int64Value
		}
	}
	return 0
}

func (x *TypedValue) GetDoubleValue() float64 {
	if x != nil {
		if x, ok := x.Value.(*TypedValue_DoubleValue); ok {
			return x.DoubleValue
		}
	}
	return 0
}

func (x *TypedValue) GetStringValue() string {
	if x != nil {
		if x, ok := x.Value.(*TypedValue_StringValue); ok {
			return x.StringValue
		}
	}
	return ""
}

func (x *TypedValue) GetDistributionValue() *distribution.Distribution {
	if x != nil {
		if x, ok := x.Value.(*TypedValue_DistributionValue); ok {
			return x.DistributionValue
		}
	}
	return nil
}

type isTypedValue_Value interface {
	isTypedValue_Value()
}

type TypedValue_BoolValue struct {
	// A Boolean value: `true` or `false`.
	BoolValue bool `protobuf:"varint,1,opt,name=bool_value,json=boolValue,proto3,oneof"`
}

type TypedValue_Int64Value struct {
	// A 64-bit integer. Its range is approximately &plusmn;9.2x10<sup>18</sup>.
	Int64Value int64 `protobuf:"varint,2,opt,name=int64_value,json=int64Value,proto3,oneof"`
}

type TypedValue_DoubleValue struct {
	// A 64-bit double-precision floating-point number. Its magnitude
	// is approximately &plusmn;10<sup>&plusmn;300</sup> and it has 16
	// significant digits of precision.
	DoubleValue float64 `protobuf:"fixed64,3,opt,name=double_value,json=doubleValue,proto3,oneof"`
}

type TypedValue_StringValue struct {
	// A variable-length string value.
	StringValue string `protobuf:"bytes,4,opt,name=string_value,json=stringValue,proto3,oneof"`
}

type TypedValue_DistributionValue struct {
	// A distribution value.
	DistributionValue *distribution.Distribution `protobuf:"bytes,5,opt,name=distribution_value,json=distributionValue,proto3,oneof"`
}

func (*TypedValue_BoolValue) isTypedValue_Value() {}

func (*TypedValue_Int64Value) isTypedValue_Value() {}

func (*TypedValue_DoubleValue) isTypedValue_Value() {}

func (*TypedValue_StringValue) isTypedValue_Value() {}

func (*TypedValue_DistributionValue) isTypedValue_Value() {}

// Describes a time interval:
//
//   - Reads: A half-open time interval. It includes the end time but
//     excludes the start time: `(startTime, endTime]`. The start time
//     must be specified, must be earlier than the end time, and should be
//     no older than the data retention period for the metric.
//   - Writes: A closed time interval. It extends from the start time to the end
//     time,
//     and includes both: `[startTime, endTime]`. Valid time intervals
//     depend on the
//     [`MetricKind`](https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors#MetricKind)
//     of the metric value. The end time must not be earlier than the start
//     time, and the end time must not be more than 25 hours in the past or more
//     than five minutes in the future.
//   - For `GAUGE` metrics, the `startTime` value is technically optional; if
//     no value is specified, the start time defaults to the value of the
//     end time, and the interval represents a single point in time. If both
//     start and end times are specified, they must be identical. Such an
//     interval is valid only for `GAUGE` metrics, which are point-in-time
//     measurements. The end time of a new interval must be at least a
//     millisecond after the end time of the previous interval.
//   - For `DELTA` metrics, the start time and end time must specify a
//     non-zero interval, with subsequent points specifying contiguous and
//     non-overlapping intervals. For `DELTA` metrics, the start time of
//     the next interval must be at least a millisecond after the end time
//     of the previous interval.
//   - For `CUMULATIVE` metrics, the start time and end time must specify a
//     non-zero interval, with subsequent points specifying the same
//     start time and increasing end times, until an event resets the
//     cumulative value to zero and sets a new start time for the following
//     points. The new start time must be at least a millisecond after the
//     end time of the previous interval.
//   - The start time of a new interval must be at least a millisecond after
//     the
//     end time of the previous interval because intervals are closed. If the
//     start time of a new interval is the same as the end time of the
//     previous interval, then data written at the new start time could
//     overwrite data written at the previous end time.
type TimeInterval struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. The end of the time interval.
	EndTime *timestamppb.Timestamp `protobuf:"bytes,2,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`
	// Optional. The beginning of the time interval.  The default value
	// for the start time is the end time. The start time must not be
	// later than the end time.
	StartTime     *timestamppb.Timestamp `protobuf:"bytes,1,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TimeInterval) Reset() {
	*x = TimeInterval{}
	mi := &file_google_monitoring_v3_common_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TimeInterval) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TimeInterval) ProtoMessage() {}

func (x *TimeInterval) ProtoReflect() protoreflect.Message {
	mi := &file_google_monitoring_v3_common_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TimeInterval.ProtoReflect.Descriptor instead.
func (*TimeInterval) Descriptor() ([]byte, []int) {
	return file_google_monitoring_v3_common_proto_rawDescGZIP(), []int{1}
}

func (x *TimeInterval) GetEndTime() *timestamppb.Timestamp {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *TimeInterval) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

// Describes how to combine multiple time series to provide a different view of
// the data.  Aggregation of time series is done in two steps. First, each time
// series in the set is _aligned_ to the same time interval boundaries, then the
// set of time series is optionally _reduced_ in number.
//
// Alignment consists of applying the `per_series_aligner` operation
// to each time series after its data has been divided into regular
// `alignment_period` time intervals. This process takes _all_ of the data
// points in an alignment period, applies a mathematical transformation such as
// averaging, minimum, maximum, delta, etc., and converts them into a single
// data point per period.
//
// Reduction is when the aligned and transformed time series can optionally be
// combined, reducing the number of time series through similar mathematical
// transformations. Reduction involves applying a `cross_series_reducer` to
// all the time series, optionally sorting the time series into subsets with
// `group_by_fields`, and applying the reducer to each subset.
//
// The raw time series data can contain a huge amount of information from
// multiple sources. Alignment and reduction transforms this mass of data into
// a more manageable and representative collection of data, for example "the
// 95% latency across the average of all tasks in a cluster". This
// representative data can be more easily graphed and comprehended, and the
// individual time series data is still available for later drilldown. For more
// details, see [Filtering and
// aggregation](https://cloud.google.com/monitoring/api/v3/aggregation).
type Aggregation struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The `alignment_period` specifies a time interval, in seconds, that is used
	// to divide the data in all the
	// [time series][google.monitoring.v3.TimeSeries] into consistent blocks of
	// time. This will be done before the per-series aligner can be applied to
	// the data.
	//
	// The value must be at least 60 seconds. If a per-series
	// aligner other than `ALIGN_NONE` is specified, this field is required or an
	// error is returned. If no per-series aligner is specified, or the aligner
	// `ALIGN_NONE` is specified, then this field is ignored.
	//
	// The maximum value of the `alignment_period` is 104 weeks (2 years) for
	// charts, and 90,000 seconds (25 hours) for alerting policies.
	AlignmentPeriod *durationpb.Duration `protobuf:"bytes,1,opt,name=alignment_period,json=alignmentPeriod,proto3" json:"alignment_period,omitempty"`
	// An `Aligner` describes how to bring the data points in a single
	// time series into temporal alignment. Except for `ALIGN_NONE`, all
	// alignments cause all the data points in an `alignment_period` to be
	// mathematically grouped together, resulting in a single data point for
	// each `alignment_period` with end timestamp at the end of the period.
	//
	// Not all alignment operations may be applied to all time series. The valid
	// choices depend on the `metric_kind` and `value_type` of the original time
	// series. Alignment can change the `metric_kind` or the `value_type` of
	// the time series.
	//
	// Time series data must be aligned in order to perform cross-time
	// series reduction. If `cross_series_reducer` is specified, then
	// `per_series_aligner` must be specified and not equal to `ALIGN_NONE`
	// and `alignment_period` must be specified; otherwise, an error is
	// returned.
	PerSeriesAligner Aggregation_Aligner `protobuf:"varint,2,opt,name=per_series_aligner,json=perSeriesAligner,proto3,enum=google.monitoring.v3.Aggregation_Aligner" json:"per_series_aligner,omitempty"`
	// The reduction operation to be used to combine time series into a single
	// time series, where the value of each data point in the resulting series is
	// a function of all the already aligned values in the input time series.
	//
	// Not all reducer operations can be applied to all time series. The valid
	// choices depend on the `metric_kind` and the `value_type` of the original
	// time series. Reduction can yield a time series with a different
	// `metric_kind` or `value_type` than the input time series.
	//
	// Time series data must first be aligned (see `per_series_aligner`) in order
	// to perform cross-time series reduction. If `cross_series_reducer` is
	// specified, then `per_series_aligner` must be specified, and must not be
	// `ALIGN_NONE`. An `alignment_period` must also be specified; otherwise, an
	// error is returned.
	CrossSeriesReducer Aggregation_Reducer `protobuf:"varint,4,opt,name=cross_series_reducer,json=crossSeriesReducer,proto3,enum=google.monitoring.v3.Aggregation_Reducer" json:"cross_series_reducer,omitempty"`
	// The set of fields to preserve when `cross_series_reducer` is
	// specified. The `group_by_fields` determine how the time series are
	// partitioned into subsets prior to applying the aggregation
	// operation. Each subset contains time series that have the same
	// value for each of the grouping fields. Each individual time
	// series is a member of exactly one subset. The
	// `cross_series_reducer` is applied to each subset of time series.
	// It is not possible to reduce across different resource types, so
	// this field implicitly contains `resource.type`.  Fields not
	// specified in `group_by_fields` are aggregated away.  If
	// `group_by_fields` is not specified and all the time series have
	// the same resource type, then the time series are aggregated into
	// a single output time series. If `cross_series_reducer` is not
	// defined, this field is ignored.
	GroupByFields []string `protobuf:"bytes,5,rep,name=group_by_fields,json=groupByFields,proto3" json:"group_by_fields,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Aggregation) Reset() {
	*x = Aggregation{}
	mi := &file_google_monitoring_v3_common_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Aggregation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Aggregation) ProtoMessage() {}

func (x *Aggregation) ProtoReflect() protoreflect.Message {
	mi := &file_google_monitoring_v3_common_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Aggregation.ProtoReflect.Descriptor instead.
func (*Aggregation) Descriptor() ([]byte, []int) {
	return file_google_monitoring_v3_common_proto_rawDescGZIP(), []int{2}
}

func (x *Aggregation) GetAlignmentPeriod() *durationpb.Duration {
	if x != nil {
		return x.AlignmentPeriod
	}
	return nil
}

func (x *Aggregation) GetPerSeriesAligner() Aggregation_Aligner {
	if x != nil {
		return x.PerSeriesAligner
	}
	return Aggregation_ALIGN_NONE
}

func (x *Aggregation) GetCrossSeriesReducer() Aggregation_Reducer {
	if x != nil {
		return x.CrossSeriesReducer
	}
	return Aggregation_REDUCE_NONE
}

func (x *Aggregation) GetGroupByFields() []string {
	if x != nil {
		return x.GroupByFields
	}
	return nil
}

var File_google_monitoring_v3_common_proto protoreflect.FileDescriptor

const file_google_monitoring_v3_common_proto_rawDesc = "" +
	"\n" +
	"!google/monitoring/v3/common.proto\x12\x14google.monitoring.v3\x1a\x1dgoogle/api/distribution.proto\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\"\xee\x01\n" +
	"\n" +
	"TypedValue\x12\x1f\n" +
	"\n" +
	"bool_value\x18\x01 \x01(\bH\x00R\tboolValue\x12!\n" +
	"\vint64_value\x18\x02 \x01(\x03H\x00R\n" +
	"int64Value\x12#\n" +
	"\fdouble_value\x18\x03 \x01(\x01H\x00R\vdoubleValue\x12#\n" +
	"\fstring_value\x18\x04 \x01(\tH\x00R\vstringValue\x12I\n" +
	"\x12distribution_value\x18\x05 \x01(\v2\x18.google.api.DistributionH\x00R\x11distributionValueB\a\n" +
	"\x05value\"\x80\x01\n" +
	"\fTimeInterval\x125\n" +
	"\bend_time\x18\x02 \x01(\v2\x1a.google.protobuf.TimestampR\aendTime\x129\n" +
	"\n" +
	"start_time\x18\x01 \x01(\v2\x1a.google.protobuf.TimestampR\tstartTime\"\xf3\a\n" +
	"\vAggregation\x12D\n" +
	"\x10alignment_period\x18\x01 \x01(\v2\x19.google.protobuf.DurationR\x0falignmentPeriod\x12W\n" +
	"\x12per_series_aligner\x18\x02 \x01(\x0e2).google.monitoring.v3.Aggregation.AlignerR\x10perSeriesAligner\x12[\n" +
	"\x14cross_series_reducer\x18\x04 \x01(\x0e2).google.monitoring.v3.Aggregation.ReducerR\x12crossSeriesReducer\x12&\n" +
	"\x0fgroup_by_fields\x18\x05 \x03(\tR\rgroupByFields\"\x8b\x03\n" +
	"\aAligner\x12\x0e\n" +
	"\n" +
	"ALIGN_NONE\x10\x00\x12\x0f\n" +
	"\vALIGN_DELTA\x10\x01\x12\x0e\n" +
	"\n" +
	"ALIGN_RATE\x10\x02\x12\x15\n" +
	"\x11ALIGN_INTERPOLATE\x10\x03\x12\x14\n" +
	"\x10ALIGN_NEXT_OLDER\x10\x04\x12\r\n" +
	"\tALIGN_MIN\x10\n" +
	"\x12\r\n" +
	"\tALIGN_MAX\x10\v\x12\x0e\n" +
	"\n" +
	"ALIGN_MEAN\x10\f\x12\x0f\n" +
	"\vALIGN_COUNT\x10\r\x12\r\n" +
	"\tALIGN_SUM\x10\x0e\x12\x10\n" +
	"\fALIGN_STDDEV\x10\x0f\x12\x14\n" +
	"\x10ALIGN_COUNT_TRUE\x10\x10\x12\x15\n" +
	"\x11ALIGN_COUNT_FALSE\x10\x18\x12\x17\n" +
	"\x13ALIGN_FRACTION_TRUE\x10\x11\x12\x17\n" +
	"\x13ALIGN_PERCENTILE_99\x10\x12\x12\x17\n" +
	"\x13ALIGN_PERCENTILE_95\x10\x13\x12\x17\n" +
	"\x13ALIGN_PERCENTILE_50\x10\x14\x12\x17\n" +
	"\x13ALIGN_PERCENTILE_05\x10\x15\x12\x18\n" +
	"\x14ALIGN_PERCENT_CHANGE\x10\x17\"\xb1\x02\n" +
	"\aReducer\x12\x0f\n" +
	"\vREDUCE_NONE\x10\x00\x12\x0f\n" +
	"\vREDUCE_MEAN\x10\x01\x12\x0e\n" +
	"\n" +
	"REDUCE_MIN\x10\x02\x12\x0e\n" +
	"\n" +
	"REDUCE_MAX\x10\x03\x12\x0e\n" +
	"\n" +
	"REDUCE_SUM\x10\x04\x12\x11\n" +
	"\rREDUCE_STDDEV\x10\x05\x12\x10\n" +
	"\fREDUCE_COUNT\x10\x06\x12\x15\n" +
	"\x11REDUCE_COUNT_TRUE\x10\a\x12\x16\n" +
	"\x12REDUCE_COUNT_FALSE\x10\x0f\x12\x18\n" +
	"\x14REDUCE_FRACTION_TRUE\x10\b\x12\x18\n" +
	"\x14REDUCE_PERCENTILE_99\x10\t\x12\x18\n" +
	"\x14REDUCE_PERCENTILE_95\x10\n" +
	"\x12\x18\n" +
	"\x14REDUCE_PERCENTILE_50\x10\v\x12\x18\n" +
	"\x14REDUCE_PERCENTILE_05\x10\f*\x9e\x01\n" +
	"\x0eComparisonType\x12\x1a\n" +
	"\x16COMPARISON_UNSPECIFIED\x10\x00\x12\x11\n" +
	"\rCOMPARISON_GT\x10\x01\x12\x11\n" +
	"\rCOMPARISON_GE\x10\x02\x12\x11\n" +
	"\rCOMPARISON_LT\x10\x03\x12\x11\n" +
	"\rCOMPARISON_LE\x10\x04\x12\x11\n" +
	"\rCOMPARISON_EQ\x10\x05\x12\x11\n" +
	"\rCOMPARISON_NE\x10\x06*a\n" +
	"\vServiceTier\x12\x1c\n" +
	"\x18SERVICE_TIER_UNSPECIFIED\x10\x00\x12\x16\n" +
	"\x12SERVICE_TIER_BASIC\x10\x01\x12\x18\n" +
	"\x14SERVICE_TIER_PREMIUM\x10\x02\x1a\x02\x18\x01B\xcd\x01\n" +
	"\x18com.google.monitoring.v3B\vCommonProtoP\x01ZAcloud.google.com/go/monitoring/apiv3/v2/monitoringpb;monitoringpb\xa2\x02\x04GMON\xaa\x02\x1aGoogle.Cloud.Monitoring.V3\xca\x02\x1aGoogle\\Cloud\\Monitoring\\V3\xea\x02\x1dGoogle::Cloud::Monitoring::V3b\x06proto3"

var (
	file_google_monitoring_v3_common_proto_rawDescOnce sync.Once
	file_google_monitoring_v3_common_proto_rawDescData []byte
)

func file_google_monitoring_v3_common_proto_rawDescGZIP() []byte {
	file_google_monitoring_v3_common_proto_rawDescOnce.Do(func() {
		file_google_monitoring_v3_common_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_google_monitoring_v3_common_proto_rawDesc), len(file_google_monitoring_v3_common_proto_rawDesc)))
	})
	return file_google_monitoring_v3_common_proto_rawDescData
}

var file_google_monitoring_v3_common_proto_enumTypes = make([]protoimpl.EnumInfo, 4)
var file_google_monitoring_v3_common_proto_msgTypes = make([]protoimpl.MessageInfo, 3)
var file_google_monitoring_v3_common_proto_goTypes = []any{
	(ComparisonType)(0),               // 0: google.monitoring.v3.ComparisonType
	(ServiceTier)(0),                  // 1: google.monitoring.v3.ServiceTier
	(Aggregation_Aligner)(0),          // 2: google.monitoring.v3.Aggregation.Aligner
	(Aggregation_Reducer)(0),          // 3: google.monitoring.v3.Aggregation.Reducer
	(*TypedValue)(nil),                // 4: google.monitoring.v3.TypedValue
	(*TimeInterval)(nil),              // 5: google.monitoring.v3.TimeInterval
	(*Aggregation)(nil),               // 6: google.monitoring.v3.Aggregation
	(*distribution.Distribution)(nil), // 7: google.api.Distribution
	(*timestamppb.Timestamp)(nil),     // 8: google.protobuf.Timestamp
	(*durationpb.Duration)(nil),       // 9: google.protobuf.Duration
}
var file_google_monitoring_v3_common_proto_depIdxs = []int32{
	7, // 0: google.monitoring.v3.TypedValue.distribution_value:type_name -> google.api.Distribution
	8, // 1: google.monitoring.v3.TimeInterval.end_time:type_name -> google.protobuf.Timestamp
	8, // 2: google.monitoring.v3.TimeInterval.start_time:type_name -> google.protobuf.Timestamp
	9, // 3: google.monitoring.v3.Aggregation.alignment_period:type_name -> google.protobuf.Duration
	2, // 4: google.monitoring.v3.Aggregation.per_series_aligner:type_name -> google.monitoring.v3.Aggregation.Aligner
	3, // 5: google.monitoring.v3.Aggregation.cross_series_reducer:type_name -> google.monitoring.v3.Aggregation.Reducer
	6, // [6:6] is the sub-list for method output_type
	6, // [6:6] is the sub-list for method input_type
	6, // [6:6] is the sub-list for extension type_name
	6, // [6:6] is the sub-list for extension extendee
	0, // [0:6] is the sub-list for field type_name
}

func init() { file_google_monitoring_v3_common_proto_init() }
func file_google_monitoring_v3_common_proto_init() {
	if File_google_monitoring_v3_common_proto != nil {
		return
	}
	file_google_monitoring_v3_common_proto_msgTypes[0].OneofWrappers = []any{
		(*TypedValue_BoolValue)(nil),
		(*TypedValue_Int64Value)(nil),
		(*TypedValue_DoubleValue)(nil),
		(*TypedValue_StringValue)(nil),
		(*TypedValue_DistributionValue)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_google_monitoring_v3_common_proto_rawDesc), len(file_google_monitoring_v3_common_proto_rawDesc)),
			NumEnums:      4,
			NumMessages:   3,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_google_monitoring_v3_common_proto_goTypes,
		DependencyIndexes: file_google_monitoring_v3_common_proto_depIdxs,
		EnumInfos:         file_google_monitoring_v3_common_proto_enumTypes,
		MessageInfos:      file_google_monitoring_v3_common_proto_msgTypes,
	}.Build()
	File_google_monitoring_v3_common_proto = out.File
	file_google_monitoring_v3_common_proto_goTypes = nil
	file_google_monitoring_v3_common_proto_depIdxs = nil
}
